#!/usr/bin/env python
from __future__ import print_function, absolute_import, division

import logging
import math
from errno import ENOENT, ENOATTR
from stat import S_IFDIR, S_IFREG
from threading import Thread
from time import time
from typing import Dict, List, Set, Tuple

from fuse import FUSE, FuseOSError, Operations, fuse_exit, LoggingMixIn
from sortedcontainers import SortedDict

import config
from disk.icmp.icmp_disk import IcmpDisk
from disk.local.local_disk import LocalDisk
from fs.inode import Inode
from hashing.rabin import RabinKarpRollingHash
from logical_block import LogicalBlock
from logical_to_physical_block_ref import LogicalToPhysicalBlockRef

if not hasattr(__builtins__, 'bytes'):
    bytes = str


class MyFS(LoggingMixIn, Operations):
    RABIN_WINDOW_SIZE = 512
    MIN_VAR_DEDUP_CHUNK_SIZE_BYTES = 32
    VAR_DEDUP_MASK = 1 << 6

    def __init__(self):
        self.file_handler = logging.FileHandler(filename='/tmp/fs', mode='w')

        self.log.handlers.clear()
        logging.getLogger().handlers.clear()

        self.log.addHandler(self.file_handler)
        self.disk = IcmpDisk()
        self.dirty_logical_blocks: Set[LogicalBlock] = set()

        self.static_dedup_data: Dict[int, Set[LogicalBlock]] = {}
        self.var_dedup_data: Dict[int, Dict[LogicalBlock, Set[Tuple[int, int]]]] = {}

        self.saved_space_total = 0

        self.physical_blocks_with_freed_data_to_be_update: Set[int] = set()

        self.window_sizes = []
        self.files: Dict[str, Inode] = {}
        self.fd = 0
        now = time()
        self.files['/'] = Inode(
            st_mode=(S_IFDIR | 0o755),
            st_ctime=now,
            st_mtime=now,
            st_atime=now,
            st_nlink=2, st_size=0)

    def is_boundary(self, hash_val):
        return hash_val & self.VAR_DEDUP_MASK == 0

    def get_boundries_for_logical_block(self, l: LogicalBlock):
        boundries = []

        r = RabinKarpRollingHash(window_size=self.RABIN_WINDOW_SIZE)
        data = memoryview(l.read())
        curr_offset = 0
        last_offset = 0

        curr_hash = None

        while curr_offset < config.BLOCK_SIZE_BYTES:
            if curr_hash is None:
                curr_hash = r.get_init_hash(data[:self.RABIN_WINDOW_SIZE])
                curr_offset = self.RABIN_WINDOW_SIZE
                data = data[self.RABIN_WINDOW_SIZE:]
            else:
                curr_hash = r.roll_hash(curr_hash, data[0])
                data = data[1:]
                curr_offset += 1

            if self.is_boundary(curr_hash):
                if curr_offset - last_offset < self.MIN_VAR_DEDUP_CHUNK_SIZE_BYTES:
                    continue
                boundries.append((last_offset, curr_offset))
                last_offset = curr_offset

        if config.BLOCK_SIZE_BYTES - last_offset:
            boundries.append((last_offset, config.BLOCK_SIZE_BYTES))

        return boundries

    def add_blocks_to_updated(self, block_ids: Set[int]):
        self.physical_blocks_with_freed_data_to_be_update.update(set(block_ids))

    def add_logical_block_to_dirty_list(self, l: LogicalBlock):
        self.dirty_logical_blocks.add(l)

    def add_data_hash_with_logical_block_static(self, data_hash: int, l: LogicalBlock):
        if data_hash not in self.static_dedup_data:
            self.static_dedup_data[data_hash] = set()

        self.static_dedup_data[data_hash].add(l)

    def add_data_hash_with_logical_block_var(self, boundray_hash: int, l: LogicalBlock, offsets: Tuple[int, int]):
        if boundray_hash not in self.var_dedup_data:
            self.var_dedup_data[boundray_hash] = {}

        if l not in self.var_dedup_data[boundray_hash]:
            self.var_dedup_data[boundray_hash][l] = set()
        self.var_dedup_data[boundray_hash][l].add(offsets)

    def remove_logical_block_from_data_hash_static(self, data_hash: int, l: LogicalBlock):
        if data_hash not in self.static_dedup_data:
            return

        try:
            self.static_dedup_data[data_hash].remove(l)
        except KeyError:
            pass

        if not self.static_dedup_data[data_hash]:
            del self.static_dedup_data[data_hash]

    def get_first_logical_block_in_data_hash_static(self, data_hash: int):
        if data_hash not in self.static_dedup_data:
            return
        return next(iter(self.static_dedup_data[data_hash]))

    def get_first_logical_block_in_data_hash_var(self, data_hash: int):
        if data_hash not in self.var_dedup_data:
            return
        return list(self.var_dedup_data[data_hash].items())[0]

    def static_dedup(self):
        for l in self.dirty_logical_blocks:
            l_hash = l.data_hash()
            existing_logical_block = self.get_first_logical_block_in_data_hash_static(l_hash)

            if existing_logical_block:
                self.add_blocks_to_updated(l.free_physical_refs())
                new_refs = SortedDict({end_offset: ref.copy(new_logical_block_id=l.lid) for (end_offset, ref) in
                                       existing_logical_block.get_logical_to_physical_refs().items()})

                ref: LogicalToPhysicalBlockRef

                l.set_logical_to_physical_refs(new_refs)

                print(f"DEDUP - DEDUPED Logical block {l.lid}")
            else:
                self.add_data_hash_with_logical_block_static(l_hash, l)
                print(f"DEDUP - ADDED Logical block {l.lid}")

        self.dirty_logical_blocks.clear()
        self.update_blocks_for_free_offsets()

    def var_dedup(self):
        for l in self.dirty_logical_blocks:
            boundaries = self.get_boundries_for_logical_block(l)
            for boundary in boundaries:
                self.window_sizes.append(boundary[1] - boundary[0])

                boundary_hash = l.data_hash_by_offset(boundary[0], boundary[1])
                existing_logical_block_tuple = self.get_first_logical_block_in_data_hash_var(boundary_hash)

                if not existing_logical_block_tuple:
                    self.add_data_hash_with_logical_block_var(boundary_hash, l, boundary)
                    print(f"VAR DEDUP - ADDED HASH with boundary {boundary}")
                else:
                    print(f"VAR DEDUP - FOUND SAME HASH FOR BOUNDARY! {existing_logical_block_tuple}")
                    existing_logical_block_obj: LogicalBlock
                    existing_logical_block_obj, offsets = existing_logical_block_tuple
                    any_offset_from_list = next(iter(offsets))
                    print(any_offset_from_list)
                    # physical_refs_by_offset = existing_logical_block_obj.get_physical_refs_by_offset(l.lid,
                    #                                                                                  any_offset_from_list[
                    #                                                                                      0],
                    #                                                                                  any_offset_from_list[
                    #                                                                                      1])
                    # print(f"PHYSICAL REFS {physical_refs_by_offset}")

                    # self.add_blocks_to_updated(l.inject_new_refs(physical_refs_by_offset))
                    self.saved_space_total += any_offset_from_list[1] - any_offset_from_list[0]

        self.dirty_logical_blocks.clear()
        # self.update_blocks_for_free_offsets()

    def chmod(self, path, mode):
        self.files[path].st_mode &= 0o770000
        self.files[path].st_mode |= mode
        return 0

    def chown(self, path, uid, gid):
        self.files[path].st_uid = uid
        self.files[path].st_gid = gid

    def create(self, path, mode):
        self.files[path] = Inode(
            st_mode=(S_IFREG | mode),
            st_nlink=1,
            st_size=0,
            st_ctime=time(),
            st_mtime=time(),
            st_atime=time())

        self.fd += 1
        return self.fd

    def getattr(self, path, fh=None):
        if path == "/FUSE_EXIT":
            fuse_exit()

        if path == "/static_dedup_now":
            self.static_dedup()
            return

        if path == "/var_dedup_now":
            self.var_dedup()
            return

        if path == "/out_window_sizes":
            with open('/tmp/windows_sizes', 'w') as f:
                import json
                f.write(json.dumps(self.window_sizes))
            return


        if path == "/show_bound":
            i = self.files['/1']
            l = i.get_logical_block_by_idx(0)
            print(self.get_boundries_for_logical_block(l))
            return

        if path == "/show_refs":
            for i in self.files.values():
                for l in i.get_all_logical_blocks():
                    print(l.get_logical_to_physical_refs())
            return

        if path not in self.files:
            raise FuseOSError(ENOENT)

        return self.files[path].__dict__

    def getxattr(self, path, name, position=0):
        attrs = self.files[path].attrs
        try:
            return attrs[name]
        except KeyError:
            raise FuseOSError(ENOATTR) # Should return ENOATTR



    def listxattr(self, path):
        attrs = self.files[path].attrs
        return attrs.keys()

    def mkdir(self, path, mode):
        self.files[path] = Inode(
            st_mode=(S_IFDIR | mode),
            st_nlink=2,
            st_size=0,
            st_ctime=time(),
            st_mtime=time(),
            st_atime=time())

        self.files['/'].st_nlink += 1

    def open(self, path, flags):
        self.fd += 1
        return self.fd

    def read(self, path, size, offset, fh):
        i = self.files[path]
        data = b''
        # print(i.get_all_logical_blocks())
        while size:
            # print(f"LEft read {size} bytes")
            logical_idx = self.offset_to_logical_block_idx(offset)
            # print(logical_idx)
            l = i.get_logical_block_by_idx(logical_idx)
            # if not l:
            #     break
            # print(l)
            offset_in_logical_block = offset - logical_idx * config.BLOCK_SIZE_BYTES
            can_read_bytes_up_to = l.block_size - offset_in_logical_block
            actually_gonna_read = can_read_bytes_up_to if size > can_read_bytes_up_to else size
            data += l.read()[offset_in_logical_block:offset_in_logical_block + actually_gonna_read]
            size -= actually_gonna_read
            offset += actually_gonna_read

        return data

    def readdir(self, path, fh):
        return ['.', '..'] + [x[1:] for x in self.files if x != '/']

    def readlink(self, path):
        raise NotImplementedError()

    def removexattr(self, path, name):
        attrs = self.files[path].attrs

        try:
            del attrs[name]
        except KeyError:
            pass  # Should return ENOATTR

    def rename(self, old, new):
        self.files[new] = self.files.pop(old)

    def rmdir(self, path):
        # with multiple level support, need to raise ENOTEMPTY if contains any files
        self.files.pop(path)
        self.files['/'].st_nlink -= 1

    def setxattr(self, path, name, value, options, position=0):
        # Ignore options
        attrs = self.files[path].attrs
        attrs[name] = value

    def statfs(self, path):

        f_blocks = int(40 * 1024 * 1024 * 1024 / config.BLOCK_SIZE_BYTES)
        f_allocated_blocks = self.disk.allocated_blocks_count

        total_bytes_available_free_offsets = self.saved_space_total + self.disk.total_bytes_available_by_free_offsets
        calc_free_blocks = int(math.floor(total_bytes_available_free_offsets / config.BLOCK_SIZE_BYTES))
        actually_used_blocks = f_allocated_blocks - calc_free_blocks

        f_bfree = f_blocks - actually_used_blocks
        f_bavail = f_bfree

        ret = dict(f_frsize=config.BLOCK_SIZE_BYTES,
                   f_bsize=config.BLOCK_SIZE_BYTES,
                   f_blocks=f_blocks,
                   f_bfree=f_bfree,
                   f_bavail=f_bavail)

        self.log.debug(ret)

        return ret

    def symlink(self, target, source):
        raise FuseOSError("Not supported")

    def truncate(self, path, length, fh=None):
        self.free_all_inode_logical_blocks(self.files[path])

    def update_blocks_for_free_offsets(self):
        for bid in self.physical_blocks_with_freed_data_to_be_update:
            self.disk.update_free_block_offsets(bid)
        self.physical_blocks_with_freed_data_to_be_update.clear()

    def free_all_inode_logical_blocks(self, f: Inode):
        for l_block in f.get_all_logical_blocks():
            self.deallocate_logical_block(l_block)
        self.update_blocks_for_free_offsets()

    def unlink(self, path):
        f: Inode = self.files.pop(path)
        self.free_all_inode_logical_blocks(f)

    def utimens(self, path, times=None):
        now = time()
        atime, mtime = times if times else (now, now)
        self.files[path].st_atime = atime
        self.files[path].st_mtime = mtime

    def offset_to_logical_block_idx(self, offset):
        return int(math.floor(offset / config.BLOCK_SIZE_BYTES))

    def allocate_logical_block(self):
        return LogicalBlock(physical_block_store=self.disk)

    def allocate_logical_block_with_physical_block(self):
        logical = self.allocate_logical_block()
        physical_offsets = self.disk.allocate_blocks_by_length(config.BLOCK_SIZE_BYTES)

        current_logical_offset_end = 0
        logical_to_physical_refs: SortedDict[int, LogicalToPhysicalBlockRef] = SortedDict()
        for allocated in physical_offsets:
            current_logical_offset_end += allocated.length
            new_logical_ref = LogicalToPhysicalBlockRef(logical_block_id=logical.lid,
                                                        end_offset=current_logical_offset_end,
                                                        physical_block_id=allocated.bid,
                                                        physical_block_start_offset=allocated.start_offset,
                                                        physical_block_end_offset=allocated.end_offset)
            # TODO unify binding to one function
            logical_to_physical_refs[current_logical_offset_end] = new_logical_ref
            # self.disk.get_block_by_id(allocated.bid).add_logical_block_ref(new_logical_ref)

        logical.set_logical_to_physical_refs(logical_to_physical_refs)
        return logical

    def allocate_logical_block_for_inode(self, inode: Inode, logical_idx):
        l = self.allocate_logical_block_with_physical_block()
        inode.attach_logical_block(logical_idx, l)
        return l

    def duplicate_logical_block_with_new_physical_block(self, l_blk: LogicalBlock):
        new_l_block = self.allocate_logical_block_with_physical_block()
        new_l_block.write(0, l_blk.read())
        return new_l_block

    def deallocate_logical_block(self, l: LogicalBlock):
        self.add_blocks_to_updated(l.free_physical_refs())
        try:
            self.remove_logical_block_from_data_hash_static(l.data_hash(), l)
            self.dirty_logical_blocks.remove(l)
        except KeyError:
            pass

    def write(self, path, data, offset, fh):
        data = data
        orig_offset = offset
        d_len = len(data)
        i = self.files[path]

        ts = []
        while data:
            # print(f"Writing {d_len} bytes to {path} to offset {offset}")
            logical_idx = self.offset_to_logical_block_idx(offset)
            l = i.get_logical_block_by_idx(logical_idx)

            if l and not l.can_write_to_logical_block_directly():
                new_l = self.duplicate_logical_block_with_new_physical_block(l)
                self.deallocate_logical_block(l)
                i.attach_logical_block(logical_idx, new_l)
                l = new_l
            elif not l:
                l = self.allocate_logical_block_for_inode(i, logical_idx)
            else:
                self.remove_logical_block_from_data_hash_static(l.data_hash(), l)

            self.add_logical_block_to_dirty_list(l)

            offset_in_logical_block = offset - logical_idx * config.BLOCK_SIZE_BYTES
            # print(f"Offset to write in logical is {offset_in_logical_block}")
            can_write_bytes = l.block_size - offset_in_logical_block

            data_to_write = data[:can_write_bytes]

            t = Thread(target=l.write, args=(offset_in_logical_block, data_to_write))
            t.daemon = True
            t.start()
            ts.append(t)

            # l.write(offset_in_logical_block, data_to_write)

            data = data[can_write_bytes:]
            offset += can_write_bytes

        [t.join() for t in ts]

        if self.files[path].st_size < orig_offset + d_len:
            self.files[path].st_size = orig_offset + d_len

        return d_len


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('mount')
    args = parser.parse_args()

    logging.basicConfig(level=logging.DEBUG)
    fuse = FUSE(MyFS(), args.mount, direct_io=False, nothreads=True, foreground=True,
                allow_other=True)
